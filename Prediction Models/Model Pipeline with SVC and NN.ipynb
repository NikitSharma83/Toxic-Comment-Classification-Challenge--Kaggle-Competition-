{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sharm\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\sharm\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier, BernoulliRBM\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the train data file\n",
    "INDATA_LOCATION = 'C:/Users/sharm/Desktop/Dat5Melb/Final_Project/Datasets/train/train_orig.csv'\n",
    "#INDATA_LOCATION = '/home/asharma/data/toxic_challenge/train.csv'\n",
    "\n",
    "# utility definitions for easier handling of the dataset column names\n",
    "TEXT_COLUMN = 'comment_text'\n",
    "CLASS_TOXIC, CLASS_SEVER_TOXIC, CLASS_OBSCENE, CLASS_THREAT, CLASS_INSULT, \\\n",
    "    CLASS_IDENTITY_HATE = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \\\n",
    "                           \"insult\", \"identity_hate\"]\n",
    "CLASSES = [CLASS_TOXIC, CLASS_SEVER_TOXIC, CLASS_OBSCENE, CLASS_THREAT, CLASS_INSULT, CLASS_IDENTITY_HATE]\n",
    "\n",
    "def read_data(filename):\n",
    "    return pd.read_csv(filename) \n",
    "\n",
    "# read the comments and associated classification data \n",
    "dataDf = read_data(INDATA_LOCATION)\n",
    "dataDf['klass_count'] = dataDf[CLASSES].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 159571\n",
      "Number data points of type toxic: 15294\n",
      "Number data points of type severe_toxic: 1595\n",
      "Number data points of type obscene: 8449\n",
      "Number data points of type threat: 478\n",
      "Number data points of type insult: 7877\n",
      "Number data points of type identity_hate: 1405\n"
     ]
    }
   ],
   "source": [
    "def basic_characteristics(df):\n",
    "    print('Number of data points: %d' %len(df))\n",
    "    for klass in CLASSES:\n",
    "        print('Number data points of type %s: %d' %(klass, len(df[df[klass]==1])))        \n",
    "basic_characteristics(dataDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    labels, counts = np.unique(dataDf[CLASSES].sum(axis=1), return_counts=True)\n",
    "    plt.bar(labels, counts, align='center')\n",
    "    plt.gca().set_title('Histogram of number of classes per datapoint')\n",
    "    plt.gca().set_xlabel('Number of classes per datapoint')\n",
    "    plt.gca().set_xticks(labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed text in vector space\n",
    "\n",
    "We use a simple count based vectorizer to embed the comment text into vector space in preparation for building classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentVectorizer:\n",
    "    def __init__(self):\n",
    "        self._vectorizers = []\n",
    "        \n",
    "    def get_count_vectorizer(self, max_features = 1000, ngram_range = (1, 2), \n",
    "                             stop_words = 'english', binary = True):\n",
    "        \"\"\"\n",
    "        Initializes a count vectorizer with parameters set by the user and \n",
    "        returns an index in the internal vector array where the vectorizer\n",
    "        has been placed. We dont want any external entity manipulating the\n",
    "        vectorizer state directly.\n",
    "        \"\"\"\n",
    "        self._vectorizers.append(CountVectorizer(max_features = max_features, \n",
    "                                                 ngram_range = ngram_range, \n",
    "                                                 stop_words = stop_words,\n",
    "                                                 binary = binary))\n",
    "        return len(self._vectorizers) - 1\n",
    "    \n",
    "    def get_tdidf_vectorizer(self, max_features = 5000, use_idf = True):\n",
    "        self._vectorizers.append(TfidfVectorizer(max_df=0.8, max_features=max_features,\n",
    "                                 min_df=2, stop_words='english',\n",
    "                                 use_idf=use_idf, ngram_range=(1,3), smooth_idf=True))\n",
    "        return len(self._vectorizers) - 1\n",
    "    \n",
    "    def doc2vec_fit_transform(self, sentences):\n",
    "        \"\"\"\n",
    "        Method for building a doc2vec model. Unfortunately it does not follow the nice fit/transform\n",
    "        pattern of the scikit models.\n",
    "        \"\"\"\n",
    "        documents = map(lambda i: TaggedDocument(sentences[i].split(), [i]),\n",
    "                        range(len(sentences)))\n",
    "        model = Doc2Vec(documents, size=5000, window=16, min_count=10, workers=8)\n",
    "        return map(lambda x: model.docvecs[x], range(len(sentences)))\n",
    "    \n",
    "    def doc2vec_transform(self, sentences):\n",
    "        vectors = []\n",
    "        for i in range(len(sentences)):\n",
    "            vectors.append(self._doc2vec_model.infer_vector(sentences[i].split()))\n",
    "        return vectors\n",
    "    \n",
    "    def _exists(self, vectorizer):\n",
    "        \"\"\"\n",
    "        Checks if the vectorizer index provided points to a valid vectorizer.\n",
    "        \"\"\"\n",
    "        if vectorizer < 0 or len(self._vectorizers) <= vectorizer:\n",
    "            raise Exception('Vectorizer index out of bound.')\n",
    "            \n",
    "        if self._vectorizers[vectorizer] == None:\n",
    "            raise Exception('Vectorizer not initialized.')\n",
    "            \n",
    "        pass\n",
    "        \n",
    "    def fit(self, comments = [], vectorizer = -1):\n",
    "        self._exists(vectorizer)\n",
    "        self._vectorizers[vectorizer].fit(comments)\n",
    "        \n",
    "    def transform(self, comments, vectorizer):\n",
    "        self._exists(vectorizer)\n",
    "        return self._vectorizers[vectorizer].transform(comments)    \n",
    "    \n",
    "    \n",
    "def get_doc2vec_model(sentences):\n",
    "    _s = sentences.tolist()\n",
    "    documents = map(lambda i: TaggedDocument(_s[i].split(), [i]), range(len(_s)))\n",
    "    return Doc2Vec(documents, size=100, window=8, min_count=30, workers=8, dm=1, hs=0, dbow_words=0, dm_concat=1)\n",
    "\n",
    "def get_doc2vec_vectors(model, sentences):\n",
    "    _s = sentences.tolist()\n",
    "    return map(lambda i: model.infer_vector(_s[i].split()), range(len(_s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a count vectorizer for this experiment    \n",
    "#commentVectorizer = CommentVectorizer()\n",
    "#vectorizer = commentVectorizer.get_tdidf_vectorizer()\n",
    "#commentVectorizer.fit(dataDf[TEXT_COLUMN], vectorizer)\n",
    "\n",
    "# embed comments into vector space\n",
    "#commentVectors = commentVectorizer.transform(dataDf[TEXT_COLUMN], vectorizer)\n",
    "\n",
    "model = get_doc2vec_model(dataDf[TEXT_COLUMN])\n",
    "print(model)\n",
    "# commentVectors = map(lambda x: model.docvecs[x], range(len(dataDf)))\n",
    "commentVectors = np.array(get_doc2vec_vectors(model, dataDf[TEXT_COLUMN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    coords = TruncatedSVD(n_components=2).fit_transform(commentVectors)\n",
    "    plt.scatter(coords[:,0], coords[:,1], color='red' )\n",
    "    plt.title('Scatter plot of the comment vectors (reduced)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create modeling and evaluation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split the dataset stratified by the number of classifications of a data point\n",
    "# for balancing across resulting modeling and evaluation datasets\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in sss.split(np.zeros(len(dataDf)), dataDf[CLASSES].sum(axis=1)):\n",
    "    pass\n",
    "\n",
    "# modeling dataset\n",
    "modeling_vectors = commentVectors[train_index]\n",
    "modeling_classes = dataDf[CLASSES].loc[train_index]\n",
    "print('Modeling data size: %d' %len(modeling_classes))\n",
    "#basic_characteristics(modeling_classes)\n",
    "\n",
    "# evaluation dataset\n",
    "evaluation_vectors = commentVectors[test_index]\n",
    "evaluation_classes = dataDf[CLASSES].loc[test_index]\n",
    "print('Evaluation data size: %d' %len(evaluation_classes))\n",
    "#basic_characteristics(evaluation_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    X = modeling_vectors\n",
    "    y = modeling_classes\n",
    "\n",
    "\n",
    "    rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "\n",
    "    param_grid = { \n",
    "        'n_estimators': [5, 10],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "    CV_rfc.fit(X, y)\n",
    "    print CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#     decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "#     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#     tol=0.001, verbose=False)\n",
    "# RandomForestClassifier(n_estimators = 100, class_weight = 'balanced', n_jobs=-1, criterion=\"entropy\", oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "class ExtendedMultiOutputClassifier(MultiOutputClassifier):\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Add a transform method to the classifier because it is mandatory for steps of a pipeline\n",
    "        to provide fit and transform methods.\n",
    "        \"\"\"\n",
    "        _o = self.predict_proba(X)\n",
    "        return np.concatenate(_o, axis=1)\n",
    "\n",
    "moc = ExtendedMultiOutputClassifier(SVC(C=1.0, cache_size=50, class_weight='balanced', decision_function_shape='ovr', gamma='auto', kernel='linear', max_iter=-1, probability=True, random_state=1, shrinking=True, tol=0.001))\n",
    "nnc = MLPClassifier(solver='sgd', activation='logistic', learning_rate='adaptive', momentum=0.9, alpha=1e-6, hidden_layer_sizes=(100, 100), random_state=1, tol=1e-15)\n",
    "# specify the order in which pipeline should execute the classifiers/estimators\n",
    "clf = Pipeline([('moc_rf', moc), ('nnc', nnc)])\n",
    "# fit all the transforms one after the other and transform the data, then fit the transformed data using the final estimator.\n",
    "clf.fit(modeling_vectors, modeling_classes)\n",
    "# rudimentary test\n",
    "predictions = clf.predict_proba(modeling_vectors)\n",
    "\n",
    "# calculate MSE (mean squared error). note np.dot on full matrix gives \n",
    "# memmory error hence the slow work around\n",
    "d = predictions - modeling_classes\n",
    "sq_difs = map(lambda x: np.dot(x, x.T), d.as_matrix())\n",
    "print('MSE: %f' %(np.sum(sq_difs) * 1.0 / len(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(evaluation_vectors)\n",
    "\n",
    "# MSE\n",
    "d = predictions - evaluation_classes\n",
    "sq_difs = map(lambda x: np.dot(x, x.T), d.as_matrix())\n",
    "print('MSE: %f' %(np.sum(sq_difs) * 1.0 / len(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#testdf = pd.read_csv('/home/asharma/data/toxic_challenge/test.csv')\n",
    "testdf = pd.read_csv('C:/Users/sharm/Desktop/Dat5Melb/Final_Project/Datasets/test1/test.csv')\n",
    "testdf.id = testdf.id.astype(basestring)\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embded test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed comments into vector space\n",
    "#testcommentVectors = commentVectorizer.transform(testdf[TEXT_COLUMN], vectorizer)\n",
    "testCommentVectors = np.array(get_doc2vec_vectors(model, testdf[TEXT_COLUMN]))\n",
    "\n",
    "testcommentVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict final probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredictions = clf.predict_proba(testcommentVectors)\n",
    "testpdf = pd.DataFrame(data=testpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissiondf = testpdf.join(testdf['id'], how='left')\n",
    "submissiondf = submissiondf[['id',0,1,2,3,4,5]]\n",
    "submissiondf.columns = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\",\"insult\", \"identity_hate\"]\n",
    "submissiondf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submissiondf.to_csv('/home/asharma/data/toxic_challenge/submission.csv', index=False)\n",
    "\n",
    "def manual_write(submissiondf,filename):\n",
    "    of = file(filename, 'w')\n",
    "    of.write('%s\\n' %','.join(submissiondf.columns))\n",
    "    for idx in range(len(submissiondf)):\n",
    "        of.write('%s\\n' %','.join(map(str, submissiondf.iloc[idx].tolist())))\n",
    "    of.close()\n",
    "\n",
    "manual_write(submissiondf, 'submission2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissiondf.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda2]",
   "language": "python",
   "name": "conda-env-Anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
